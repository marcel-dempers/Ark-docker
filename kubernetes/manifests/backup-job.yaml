apiVersion: v1
kind: ServiceAccount
metadata:
  name: ark-backup
  namespace: arkmanager
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: arkmanager
  name: ark-backup
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ark-backup
  namespace: arkmanager
subjects:
- kind: ServiceAccount
  name: ark-backup
  namespace: arkmanager
roleRef:
  kind: Role
  name: ark-backup
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ark-backup
  namespace: arkmanager
spec:
  schedule: "0 13,23 * * *"
  timeZone: "Australia/Melbourne"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: ark-backup
            image: aimvector/kube-tools:latest
            command:
            - "/bin/sh"
            - "-c"
            - "kubectl exec -it arkmanager-0 -- bash -c 'arkmanager saveworld @all && arkmanager backup @all'"
            - "kubectl exec -it arkmanager-0 -- bash -c 'rm -rf /ark/backups/*'" #cleanup old local backups as above sends to S3
          restartPolicy: OnFailure
          serviceAccountName: ark-backup